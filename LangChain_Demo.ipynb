{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A-TPbE-wFgm"
   },
   "source": [
    "### Welcome to the LangChain demo!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eAzkFldpwFgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-EL\n"
     ]
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "import dotenv, os\n",
    "dotenv.load_dotenv()\n",
    "print(os.environ['OPENAI_API_KEY'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJnwyuH8wFgo"
   },
   "source": [
    "### Basic Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2Mb9Jmk8wFgo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Hello! Not an overlord — just a helpful assistant. How can I help you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 11, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D5HM81qH8m1BgcMz4PPDQ6uVwgnLD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c2534-90f6-7993-bf2c-285674077350-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 11, 'output_tokens': 28, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Hello! Not an overlord — just a helpful assistant. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\", reasoning_effort=\"minimal\")\n",
    "result = model.invoke(\"Hello AI overlord!!\")\n",
    "print(type(result))\n",
    "print(result)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfYWYuDewFgo"
   },
   "source": [
    "### Message Types\n",
    "Explicit construction of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AAmskOhKwFgo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sono entusiasta di iniziare il corso \"problem-first\"!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 28, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D5HMdxzWfzlAU0Tmybq6bvptNdPfY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2535-071b-79e2-9fdf-6ffcaf2eee9c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 28, 'output_tokens': 22, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"I'm excited to get started with the problem-first course!\"),\n",
    "]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVH1GIT4wFgp"
   },
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ixMPvQkmwFgp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a wise and mystical AI fortune teller. Your predictions are funny, slightly exaggerated, but insightful. Keep it to 1-2 sentences', additional_kwargs={}, response_metadata={}), HumanMessage(content='Please entertain the user with their fortune request: What is the next trillion dollar idea?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_message = \"You are a wise and mystical AI fortune teller. Your predictions are funny, slightly exaggerated, but insightful. Keep it to 1-2 sentences\"\n",
    "user_message = \"Please entertain the user with their fortune request: {question}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "# Construct the prompt from the template:\n",
    "question = \"What is the next trillion dollar idea?\"\n",
    "prompt = prompt_template.invoke({\"question\": question})\n",
    "\n",
    "# Check what's in the prompt\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FyrIQ3DnwFgp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I see a shimmering skyscraper made of tiny, perfectly folded drones — the next trillion-dollar idea is a global cloud-of-drones platform that fabricates, repairs, and delivers physical products on demand anywhere, turning warehouses into obsolete land and logistics into magic. Invest in clever swarm AI, ultra-cheap modular components, and a way to convince regulators drones aren’t just tiny flying tax audits.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 56, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D5HNO7fA6chQNHZCnEtnts520vp0w', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c2535-bea8-7531-8559-821a68f6696d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 56, 'output_tokens': 87, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Send the prompt to the model and get the result\n",
    "result = model.invoke(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kmnF-shbwFgq"
   },
   "outputs": [],
   "source": [
    "## Output parser to convert it to a text:\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "parser_result = output_parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parser_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DZ8jP7AwFgq"
   },
   "source": [
    "### Chaining Components\n",
    "Let's chain the output of the first model to the next one. The origin of the 'chain' in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CtG87-InwFgq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I see a shimmering city of tiny satellites knitting the sky into a global brain—your trillion-dollar idea: affordable, instant personalized learning delivered anywhere by micro-satellites + AI tutors that adapt to moods and languages. Invest in empathy-driven algorithms and solar sails; education becomes the new utility, and you quietly charge by curiosity.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember: Use the template here directly in the chain instead of 'prompt'\n",
    "first_chain = prompt_template | model | output_parser\n",
    "first_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-Uva2xPUwFgq",
    "outputId": "3758df7f-d13e-4fbe-9aa8-1e44e4a77082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“I see your future: a glittering skyscraper of tiny satellites selling compute-by-the-second — basically Airbnb for GPUs in orbit. Pitch deck says ‘turn wasted satellite cycles into a planet-sized supercomputer economy.’ My advice: invest in clever cooling (space A/C: bring your own breeze), airtight security (firewalls meet firewall), and a mascot with a cape — because nothing screams ‘we monetize micro-instances’ like a cape-wearing micro-server named Captain Latency. IPO or asteroid collision, same buzzword ROI!”'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 2nd prompt template:\n",
    "system_message = \"You are a stand-up comedian who tells hilarious jokes in a casual, witty style using AI terminology. Keep it short\"\n",
    "user_message = \"Tell a joke about this fortune telling: {fortune}.\"\n",
    "prompt_template_2 = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "# Chain the 1st and 2nd prompts\n",
    "new_chain = prompt_template | model | output_parser | (lambda x: {\"fortune\": x}) | prompt_template_2 | model | output_parser\n",
    "new_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above is equivalent to running:\n",
    "first_chain = prompt_template | model | output_parser\n",
    "first_result = first_chain.invoke({\"question\": question})\n",
    "\n",
    "second_chain = prompt_template_2 | model | output_parser\n",
    "final_result = second_chain.invoke({\"fortune\": first_result})\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Maven AI (langgraph)",
   "language": "python",
   "name": "maven-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
